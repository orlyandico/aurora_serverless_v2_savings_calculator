{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf208013",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate potential savings in USD from moving your existing RDS fleet to Aurora Serverless V2\n",
    "#\n",
    "# BUGS\n",
    "# - hard-wired Aurora Serverless V2 ACU pricing\n",
    "# - assumes all On-Demand, does not factor in Reserved Instances\n",
    "# - assumes 1 ACU = 0.25 vCPU which (probably) is fine for now but may change\n",
    "# - doesn't work well for burstable instances (assumes that they are equivalent to regular instances)\n",
    "# - not tested on account with large number of DB instances (does describe_db_instances paginate?)\n",
    "# - requires that your AWS CLI is properly set up and with proper AWS access/secret keys and region\n",
    "# - only queries RDS fleet in current region (defined in AWS CLI configuration)\n",
    "# - does not factor in storage cost savings when moving from MAZ RDS (non-Aurora) to Aurora\n",
    "#\n",
    "#\n",
    "# THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED\n",
    "# TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL\n",
    "# THE AUTHOR OR COPYRIGHT HOLDER BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF\n",
    "# CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS\n",
    "# IN THE SOFTWARE.\n",
    "#\n",
    "# receiver of blame: orly.andico@gmail.com\n",
    "\n",
    "import boto3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import date, timedelta, datetime\n",
    "import json\n",
    "import math\n",
    "import os\n",
    "\n",
    "client = boto3.client('rds')\n",
    "cw = boto3.client('cloudwatch')\n",
    "sess = boto3.session.Session()\n",
    "region = sess.region_name\n",
    "\n",
    "print(region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a87ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.describe_db_instances()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94773da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "df = pd.concat([df, pd.DataFrame(response['DBInstances']) ], ignore_index=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ae05597",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.filter(['DBInstanceIdentifier','DBInstanceClass','Engine', 'DBInstanceStatus', 'AllocatedStorage', 'SecondaryAvailabilityZone'], axis=1)\n",
    "df2 = df2.astype({\"AllocatedStorage\": int, \"SecondaryAvailabilityZone\": str})\n",
    "\n",
    "# we need to remove DBInstanceClass = \"db.serverless\" which corresponds to serverless v2\n",
    "# serverless v1 does not show up in describe_db_instances\n",
    "df2 = df2[ df2['DBInstanceClass'] != 'db.serverless'].reset_index(drop=True)\n",
    "\n",
    "# we also need to remove any databases which aren't supported (i.e. not MySQL or PostgreSQL)\n",
    "df2 = df2[ df2['Engine'].isin(['aurora-mysql', 'mysql', 'aurora-postgresql', 'postgresql'])]\n",
    "\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "440f29c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract pricing data\n",
    "# this only really works for MySQL and PostgreSQL because we hard-wire the no license required\n",
    "def get_rds_instance_hourly_price(region_name, instance_type, database_engine, deployment_option):\n",
    "\n",
    "    filters = [\n",
    "        {'Type': 'TERM_MATCH', 'Field': 'instanceType', 'Value': instance_type},\n",
    "        {'Type': 'TERM_MATCH', 'Field': 'databaseEngine', 'Value': database_engine},\n",
    "        {'Type': 'TERM_MATCH', 'Field': 'licenseModel', 'Value': 'No License required'},\n",
    "        {'Type': 'TERM_MATCH', 'Field': 'deploymentOption', 'Value': deployment_option},        \n",
    "        {'Type': 'TERM_MATCH', 'Field': 'regionCode', 'Value': region_name}\n",
    "    ]\n",
    "    \n",
    "#    print (\"DEBUG: \", filters)\n",
    "\n",
    "    pricing_client = boto3.client('pricing', region_name='us-east-1')    \n",
    "    response = pricing_client.get_products(ServiceCode='AmazonRDS', Filters=filters, MaxResults=1)\n",
    "\n",
    "    j = json.loads(response['PriceList'][0])\n",
    "    od = j['terms']['OnDemand']\n",
    "    id1 = list(od)[0]\n",
    "    id2 = list(od[id1]['priceDimensions'])[0]\n",
    "\n",
    "    price_od = od[id1]['priceDimensions'][id2]['pricePerUnit']['USD']\n",
    "\n",
    "    r = {\n",
    "        'vcpu': j['product']['attributes']['vcpu'],\n",
    "        'memory': j['product']['attributes']['memory'],\n",
    "        'pricePerUnit': price_od,\n",
    "        'instanceType': j['product']['attributes']['instanceType'],\n",
    "        'databaseEngine': j['product']['attributes']['databaseEngine'],\n",
    "        'deploymentOption': j['product']['attributes']['deploymentOption']\n",
    "    }\n",
    "    return (r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb355e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetch the pricing for every row in the RDS instances\n",
    "\n",
    "nrows = len(df2.index)\n",
    "idx = 0\n",
    "\n",
    "# iterate over all rows in dataframe\n",
    "while (idx < nrows):\n",
    "    db = df2.iloc[idx]['Engine']\n",
    "    az = df2.iloc[idx]['SecondaryAvailabilityZone']\n",
    "    if (len(az) > 4):\n",
    "        deploymentOption = 'Multi-AZ'\n",
    "    else:\n",
    "        deploymentOption = 'Single-AZ'\n",
    "    \n",
    "    ic = df2.iloc[idx]['DBInstanceClass']\n",
    "    \n",
    "    if (db == 'mysql'):\n",
    "        databaseEngine = 'MySQL'\n",
    "    elif (db == 'aurora-mysql'):\n",
    "        databaseEngine = 'Aurora MySQL'\n",
    "    elif (db == 'postgresql'):\n",
    "        databaseEngine = 'PostgreSQL'\n",
    "    elif (db == 'aurora-postgresql'):\n",
    "        databaseEngine = 'Aurora PostgreSQL'\n",
    "    else:\n",
    "        databaseEngine = 'MySQL'\n",
    "    \n",
    "    \n",
    "    r = get_rds_instance_hourly_price(region, ic, databaseEngine, deploymentOption)\n",
    "    \n",
    "    # sanity check that we got the correct match\n",
    "    if (ic == r['instanceType'] and\n",
    "        databaseEngine == r['databaseEngine'] and\n",
    "       deploymentOption == r['deploymentOption']):\n",
    "        \n",
    "        r['memory'] = r['memory'].replace(\" GiB\", \"\") \n",
    "        \n",
    "        r['memory'] = float(r['memory'])\n",
    "        r['pricePerUnit'] = float(r['pricePerUnit'])\n",
    "        r['vcpu'] = float(r['vcpu'])\n",
    "\n",
    "        if (deploymentOption == 'Multi-AZ'):\n",
    "            num = 2\n",
    "        else:\n",
    "            num = 1\n",
    "            \n",
    "        print(r, \"\\n\")\n",
    "        df2.loc[idx, ['pricePerUnit', 'deploymentOption', 'vcpu', 'memory', 'pricePerMonth']] = [r['pricePerUnit'], r['deploymentOption'], r['vcpu'], r['memory'], r['pricePerUnit'] * 730 * num ]\n",
    "                                                                                \n",
    "    idx = idx + 1\n",
    "                                                            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d6314d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c40caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can only fetch 1440 data points from Cloudwatch, so over a 2-week period (20160 minutes)\n",
    "# our sampling interval is 14 minutes; also note we are fetching the *MAXIMUM* over each sampling period\n",
    "# however, let's use a less aggressive 1-hour sampling interval\n",
    "\n",
    "dfutil = pd.DataFrame()\n",
    "\n",
    "for dbid in df2['DBInstanceIdentifier']:\n",
    "    stats = cw.get_metric_statistics(\n",
    "        Namespace='AWS/RDS',\n",
    "        Dimensions=[\n",
    "            {\n",
    "                'Name': 'DBInstanceIdentifier',\n",
    "                'Value': dbid\n",
    "            }\n",
    "        ],\n",
    "        MetricName='CPUUtilization',\n",
    "        StartTime=datetime.now() - timedelta(days=14),\n",
    "        EndTime=datetime.now(),\n",
    "        Period=3600,\n",
    "        Statistics=[ 'Maximum' ])\n",
    "    df3 = pd.DataFrame(stats['Datapoints'])\n",
    "    df3['DBInstanceIdentifier'] = dbid\n",
    "\n",
    "    dfutil = pd.concat([dfutil, df3], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50f901bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "094db9bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each DBInstanceIdentifier, get the average and maximum CPU utilization\n",
    "df_agg = dfutil.groupby(\"DBInstanceIdentifier\").Maximum.agg([\"mean\", \"std\", \"max\", \"count\"]).reset_index()\n",
    "df_agg['threeSigma'] = df_agg['mean'] + 3*df_agg['std']\n",
    "df_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa77cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined = pd.merge(df2, df_agg)\n",
    "df_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df56a655",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 GB RAM = 1 ACU, and very roughly, 1 ACU = 0.25 vCPU\n",
    "# we currently do not recommend < 2 ACU for various reasons.. (although 0.5 ACU is the stated minimum)\n",
    "df_combined['acu_usage'] = df_combined['mean'] * df_combined['vcpu'] * 4 / 50\n",
    "df_combined['acu_usage'] = df_combined['acu_usage'].apply(np.floor) + 0.5\n",
    "df_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d30cac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "### FIXME: haven't figured out how to extract ACU pricing from the Pricing API\n",
    "### hard-wiring for now, currently APG/AMS Serverless V2 ACU pricing is identical\n",
    "### also.. no GovCloud\n",
    "### https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/Concepts.RegionsAndAvailabilityZones.html\n",
    "\n",
    "v2_pricing = {\n",
    "    'ap-east-1': 0.22,\n",
    "    'ap-northeast-1': 0.20,\n",
    "    'ap-northeast-2': 0.20,\n",
    "    'ap-south-1': 0.18,\n",
    "    'ap-southeast-1': 0.20,\n",
    "    'ap-southeast-2': 0.20,\n",
    "    'ca-central-1': 0.14,\n",
    "    'eu-central-1': 0.14,\n",
    "    'eu-north-1': 0.14,\n",
    "    'eu-west-1': 0.14,\n",
    "    'eu-west-2': 0.14,\n",
    "    'eu-west-3': 0.14,\n",
    "    'sa-east-1': 0.25,\n",
    "    'us-east-1': 0.12,\n",
    "    'us-east-2': 0.12,\n",
    "    'us-west-1': 0.16,\n",
    "    'us-west-2': 0.12,\n",
    "}\n",
    "\n",
    "df_pricing = pd.DataFrame.from_dict(v2_pricing, orient='index').reset_index()\n",
    "\n",
    "df_pricing.columns=[ 'regionCode', 'pricePerAcu']\n",
    "df_pricing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7de3c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prevent this from bombing out unceremoniously if the current region is not one where ServerlessV2 is available\n",
    "# (via the above hard-wired pricing list)\n",
    "try:\n",
    "    ppa = df_pricing[ df_pricing['regionCode'] == region ].values[0][1]\n",
    "except KeyError:\n",
    "    # large value to bloat the cost\n",
    "    ppa = 999999\n",
    "    \n",
    "#df_combined['acuPricePerMonth'] = df_combined['acu_usage'] * ppa * 730\n",
    "\n",
    "df_combined['acuPricePerMonth'] = np.where(df_combined['deploymentOption'] == 'Single-AZ',\n",
    "                                           df_combined['acu_usage'] * ppa * 730,\n",
    "                                          df_combined['acu_usage'] * ppa * 730 * 2)\n",
    "\n",
    "df_combined['potentialSavings'] = np.where(df_combined['acuPricePerMonth'] < df_combined['pricePerMonth'],\n",
    "                                           df_combined['pricePerMonth'] - df_combined['acuPricePerMonth'], 0)\n",
    "\n",
    "pid = os.getpid()\n",
    "outputfile = \"aurora_serverless_tco_%06d.csv\" % pid\n",
    "df_combined.to_csv(outputfile, index=False)\n",
    "\n",
    "print(\"Wrote output file %s\" % outputfile)\n",
    "df_combined"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
